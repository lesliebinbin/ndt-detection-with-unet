{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79cf58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = Path(\"valid-versus-invalid\").name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea6cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "epochs = 120\n",
    "\n",
    "\n",
    "# Learning rate scheduler\n",
    "def cosine_annealing_scheduler(epoch, lr):\n",
    "    initial_lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    T_max = int(epochs / 2)\n",
    "\n",
    "    cosine_decay = 0.5 * (1 + np.cos(np.pi * (epoch % T_max) / T_max))\n",
    "    new_lr = (initial_lr - min_lr) * cosine_decay + min_lr\n",
    "\n",
    "    return float(new_lr)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "\n",
    "# Load datasets using Keras utilities\n",
    "batch_size = 8\n",
    "img_size = (640, 640)\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    f\"{temp_folder}/train\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    pad_to_aspect_ratio=True\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    f\"{temp_folder}/valid\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    pad_to_aspect_ratio=True\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_train = []\n",
    "for _, labels in train_ds:\n",
    "    # class_indices = labels.numpy()\n",
    "    class_indices = np.argmax(labels.numpy(), axis=1)\n",
    "    y_train.extend(class_indices)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=np.unique(y_train), y=y_train\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "class_weights\n",
    "\n",
    "# Get class names\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "input_shape = (640, 640, 1)\n",
    "\n",
    "# model = new_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConfusionMatrixCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, val_data, class_names=None, log_dir=\"logs\"):\n",
    "        super().__init__()\n",
    "        self.val_data = val_data\n",
    "        self.class_names = class_names\n",
    "        self.file_writer = tf.summary.create_file_writer(f\"{log_dir}/cm\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for images, labels in self.val_data:\n",
    "            preds = self.model.predict(images, verbose=0)\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "            y_pred.extend(preds)\n",
    "            true_labels = np.argmax(labels.numpy(), axis=1)\n",
    "            y_true.extend(true_labels)\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        # Count-based confusion matrix\n",
    "        cm_counts = confusion_matrix(y_true, y_pred)\n",
    "        fig1, ax1 = plt.subplots(figsize=(10, 10))\n",
    "        disp_counts = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=cm_counts, display_labels=self.class_names\n",
    "        )\n",
    "        disp_counts.plot(ax=ax1, cmap=\"Blues\", values_format=\"d\")\n",
    "        ax1.set_title(f\"Confusion Matrix (Counts) - Epoch {epoch}\")\n",
    "        buf1 = io.BytesIO()\n",
    "        plt.savefig(buf1, format=\"png\")\n",
    "        plt.close(fig1)\n",
    "        buf1.seek(0)\n",
    "        image1 = tf.image.decode_png(buf1.getvalue(), channels=4)\n",
    "        image1 = tf.expand_dims(image1, 0)\n",
    "\n",
    "        # Percentage-based confusion matrix\n",
    "        cm_percent = (\n",
    "            cm_counts.astype(\"float\") / cm_counts.sum(axis=1, keepdims=True) * 100\n",
    "        )\n",
    "        fig2, ax2 = plt.subplots(figsize=(10, 10))\n",
    "        disp_percent = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=cm_percent, display_labels=self.class_names\n",
    "        )\n",
    "        disp_percent.plot(ax=ax2, cmap=\"Oranges\", values_format=\".1f\")\n",
    "        ax2.set_title(f\"Confusion Matrix (Percentage) - Epoch {epoch}\")\n",
    "        buf2 = io.BytesIO()\n",
    "        plt.savefig(buf2, format=\"png\")\n",
    "        plt.close(fig2)\n",
    "        buf2.seek(0)\n",
    "        image2 = tf.image.decode_png(buf2.getvalue(), channels=4)\n",
    "        image2 = tf.expand_dims(image2, 0)\n",
    "\n",
    "        # Log both images to TensorBoard\n",
    "        with self.file_writer.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix - Counts\", image1, step=epoch)\n",
    "            tf.summary.image(\"Confusion Matrix - Percentage\", image2, step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2363aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b273783",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f\"models/{temp_folder}_best_val_acc.keras\", save_best_only=True, monitor=\"val_acc\"\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f\"models/{temp_folder}_best_val_loss.keras\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=int(epochs / 2)),\n",
    "    keras.callbacks.TensorBoard(log_dir=\"logs\"),\n",
    "    keras.callbacks.LearningRateScheduler(cosine_annealing_scheduler, verbose=1),\n",
    "    ConfusionMatrixCallback(val_ds, class_names=class_names),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import (\n",
    "    build_resnet,\n",
    "    build_simple_cnn,\n",
    "    RandomSmoothingModel,\n",
    "    RandomSmoothingLoss,\n",
    ")\n",
    "\n",
    "base_backbone = keras.models.load_model(\n",
    "    \"models/valid-v-invalid.keras\", compile=False\n",
    ").get_layer(\"resnet_18_imagenet\")\n",
    "base_model = build_resnet(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    preset=\"resnet_18_imagenet\",\n",
    "    should_scale=True,\n",
    ")\n",
    "model = RandomSmoothingModel(inputs=base_model.inputs, outputs=base_model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb734837",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=RandomSmoothingLoss(keras.losses.CategoricalCrossentropy(), smoothing_range=(0.0, 0.1)),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3, weight_decay=1e-6),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    ")\n",
    "\n",
    "score = model.evaluate(val_ds, verbose=0)\n",
    "print(f\"Test loss: {score[0]}\")\n",
    "print(f\"Test accuracy: {score[1]}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98aec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031f33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh-computer-vision (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433adb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow import keras\n",
    "\n",
    "epochs = 120\n",
    "\n",
    "\n",
    "# Learning rate scheduler\n",
    "def cosine_annealing_scheduler(epoch, lr):\n",
    "    initial_lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    T_max = int(epochs / 2)\n",
    "\n",
    "    cosine_decay = 0.5 * (1 + np.cos(np.pi * (epoch % T_max) / T_max))\n",
    "    new_lr = (initial_lr - min_lr) * cosine_decay + min_lr\n",
    "\n",
    "    return float(new_lr)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "\n",
    "# Load datasets using Keras utilities\n",
    "batch_size = 32\n",
    "img_size = (512, 512)\n",
    "\n",
    "# train_ds = image_dataset_from_directory(\n",
    "#     \"official_data/train\",\n",
    "#     label_mode=\"categorical\",\n",
    "#     image_size=img_size,\n",
    "#     batch_size=batch_size,\n",
    "#     color_mode=\"grayscale\",\n",
    "# )\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    \"official_data/valid\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    ")\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "    \"official_data/test\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cec814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_stats(dataset):\n",
    "    pixel_values = []\n",
    "    for images, _ in dataset:\n",
    "        pixel_values.extend(images.numpy().flatten())\n",
    "    \n",
    "    return {\n",
    "        'mean': np.mean(pixel_values),\n",
    "        'std': np.std(pixel_values),\n",
    "        'min': np.min(pixel_values),\n",
    "        'max': np.max(pixel_values),\n",
    "        'histogram': np.histogram(pixel_values, bins=256, range=(0, 255))[0]\n",
    "    }\n",
    "\n",
    "# train_stats = dataset_stats(train_ds)\n",
    "val_stats = dataset_stats(val_ds)\n",
    "test_stats = dataset_stats(test_ds)\n",
    "\n",
    "# print(\"Train stats:\", train_stats)\n",
    "print(\"Val stats:\", val_stats)\n",
    "print(\"Test stats:\", test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905bc721",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(val_stats['histogram'], alpha=0.5, label='Val', bins=256, range=(0, 255))\n",
    "plt.hist(test_stats['histogram'], alpha=0.5, label='Test', bins=256, range=(0, 255))\n",
    "plt.legend()\n",
    "plt.title(\"Pixel Value Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a405d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_features(dataset, sample_size=1000):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for batch_images, batch_labels in dataset.take(sample_size // batch_size + 1):\n",
    "        flattened = batch_images.numpy().reshape(len(batch_images), -1)  # Flatten images\n",
    "        features.extend(flattened)\n",
    "        labels.extend(np.argmax(batch_labels.numpy(), axis=1))\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Sample subsets (for speed)\n",
    "X_val, y_val = extract_features(val_ds)\n",
    "X_test, y_test = extract_features(test_ds)\n",
    "\n",
    "# PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_val_pca = pca.fit_transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_val_pca[:, 0], X_val_pca[:, 1], alpha=0.3, marker='x', label='Val', c=y_val)\n",
    "plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], alpha=0.3, marker='^', label='Test', c=y_test)\n",
    "plt.legend()\n",
    "plt.title(\"PCA of Train/Val/Test Sets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aae7f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh-computer-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79cf58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "first_label = \"circle\"\n",
    "second_label = \"lack_of_fusion\"\n",
    "\n",
    "src_folder = \"dataset_by_aspect_ratio\"\n",
    "import shutil\n",
    "\n",
    "\n",
    "def prepare_data(src_folder: str | Path, *labels) -> str:\n",
    "    if isinstance(src_folder, str):\n",
    "        src_folder = Path(src_folder)\n",
    "    temporarily_folder = \"-versus-\".join(labels)\n",
    "    temporarily_folder = Path(temporarily_folder)\n",
    "    temporarily_folder.mkdir(parents=True, exist_ok=True)\n",
    "    for file in src_folder.rglob(\"**/*.jpg\"):\n",
    "        if file.parent.name in labels:\n",
    "            rel_path = file.relative_to(src_folder)\n",
    "            tgt_path = temporarily_folder / rel_path\n",
    "            tgt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy(file, tgt_path)\n",
    "    return temporarily_folder.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2b01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = prepare_data(src_folder, first_label, second_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea6cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "epochs = 120\n",
    "\n",
    "\n",
    "# Learning rate scheduler\n",
    "def cosine_annealing_scheduler(epoch, lr):\n",
    "    initial_lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "    T_max = int(epochs / 2)\n",
    "\n",
    "    cosine_decay = 0.5 * (1 + np.cos(np.pi * (epoch % T_max) / T_max))\n",
    "    new_lr = (initial_lr - min_lr) * cosine_decay + min_lr\n",
    "\n",
    "    return float(new_lr)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from utils import create_images_dataset\n",
    "\n",
    "\n",
    "# Load datasets using Keras utilities\n",
    "batch_size = 32\n",
    "img_size = (512, 512)\n",
    "\n",
    "class_names = [first_label, second_label]\n",
    "\n",
    "train_ds = create_images_dataset(\n",
    "    f\"{temp_folder}/train\",\n",
    "    class_names=class_names,\n",
    "    target_size=img_size,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "val_ds = create_images_dataset(\n",
    "    f\"{temp_folder}/valid\",\n",
    "    class_names=class_names,\n",
    "    target_size=img_size,\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "train_ds = train_ds.shuffle(100).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_val = []\n",
    "for _, labels in val_ds:\n",
    "    # class_indices = labels.numpy()\n",
    "    class_indices = np.argmax(labels.numpy(), axis=1)\n",
    "    y_val.extend(class_indices)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=np.unique(y_val), y=y_val\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "class_weights\n",
    "\n",
    "# Get class names\n",
    "num_classes = len(class_names)\n",
    "input_shape = (512, 512, 1)\n",
    "\n",
    "# model = new_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConfusionMatrixCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, val_data, class_names=None, log_dir=\"logs\"):\n",
    "        super().__init__()\n",
    "        self.val_data = val_data\n",
    "        self.class_names = class_names\n",
    "        self.file_writer = tf.summary.create_file_writer(f\"{log_dir}/cm\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for images, labels in self.val_data:\n",
    "            preds = self.model.predict(images, verbose=0)\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "            y_pred.extend(preds)\n",
    "            true_labels = np.argmax(labels.numpy(), axis=1)\n",
    "            y_true.extend(true_labels)\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        # Count-based confusion matrix\n",
    "        cm_counts = confusion_matrix(y_true, y_pred)\n",
    "        fig1, ax1 = plt.subplots(figsize=(10, 10))\n",
    "        disp_counts = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=cm_counts, display_labels=self.class_names\n",
    "        )\n",
    "        disp_counts.plot(ax=ax1, cmap=\"Blues\", values_format=\"d\")\n",
    "        ax1.set_title(f\"Confusion Matrix (Counts) - Epoch {epoch}\")\n",
    "        buf1 = io.BytesIO()\n",
    "        plt.savefig(buf1, format=\"png\")\n",
    "        plt.close(fig1)\n",
    "        buf1.seek(0)\n",
    "        image1 = tf.image.decode_png(buf1.getvalue(), channels=4)\n",
    "        image1 = tf.expand_dims(image1, 0)\n",
    "\n",
    "        # Percentage-based confusion matrix\n",
    "        cm_percent = (\n",
    "            cm_counts.astype(\"float\") / cm_counts.sum(axis=1, keepdims=True) * 100\n",
    "        )\n",
    "        fig2, ax2 = plt.subplots(figsize=(10, 10))\n",
    "        disp_percent = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=cm_percent, display_labels=self.class_names\n",
    "        )\n",
    "        disp_percent.plot(ax=ax2, cmap=\"Oranges\", values_format=\".1f\")\n",
    "        ax2.set_title(f\"Confusion Matrix (Percentage) - Epoch {epoch}\")\n",
    "        buf2 = io.BytesIO()\n",
    "        plt.savefig(buf2, format=\"png\")\n",
    "        plt.close(fig2)\n",
    "        buf2.seek(0)\n",
    "        image2 = tf.image.decode_png(buf2.getvalue(), channels=4)\n",
    "        image2 = tf.expand_dims(image2, 0)\n",
    "\n",
    "        # Log both images to TensorBoard\n",
    "        with self.file_writer.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix - Counts\", image1, step=epoch)\n",
    "            tf.summary.image(\"Confusion Matrix - Percentage\", image2, step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b273783",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f\"models/{temp_folder}_best_val_acc.keras\", save_best_only=True, monitor=\"val_acc\"\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f\"models/{temp_folder}_best_val_loss.keras\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=int(epochs / 4)),\n",
    "    keras.callbacks.TensorBoard(log_dir=\"logs\"),\n",
    "    keras.callbacks.LearningRateScheduler(cosine_annealing_scheduler, verbose=1),\n",
    "    ConfusionMatrixCallback(val_ds, class_names=class_names),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from layers import build_resnet, build_simple_cnn\n",
    "\n",
    "model = build_resnet(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    preset=\"resnet_18_imagenet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb734837",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # loss=RandomSmoothingLoss(keras.losses.CategoricalCrossentropy(), smoothing_range=(0.0, 0.1)),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3, weight_decay=1e-6),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    ")\n",
    "\n",
    "score = model.evaluate(val_ds, verbose=0)\n",
    "print(f\"Test loss: {score[0]}\")\n",
    "print(f\"Test accuracy: {score[1]}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b98aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(Path(temp_folder), ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031f33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh-computer-vision (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
